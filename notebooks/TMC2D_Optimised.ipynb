{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "sys.path.insert(1, '/home/nicolas/code/src')\n",
    "sys.path.insert(1, '/home/nicolas/code/data')\n",
    "\n",
    "from TMCRBM import TMCRBM\n",
    "from scipy.integrate import simps\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float\n",
    "torch.set_num_threads(4)\n",
    "data = torch.tensor(np.genfromtxt('../dataset/data_2d.dat'), device = device, dtype = dtype)\n",
    "\n",
    "data = (data+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"../model/AllParametersTMC2DRBM_NGibbs_30_Nh100_Nv1000_Nmb200_Nepoch100_lr_0.1_N20000_Npoint2500_Nchain10.h5\", 'r')\n",
    "alltimes = np.array(f['alltime'])\n",
    "alltimes = []\n",
    "for t in f['alltime'][:]:\n",
    "    if 'W'+str(t) in f:\n",
    "        alltimes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.zeros(10, len(alltimes), device = device)\n",
    "for i in range(len(alltimes)):\n",
    "    t = alltimes[i]\n",
    "    _, tmpS, tmpV = torch.svd(torch.tensor(f['W'+str(t)], device = device))\n",
    "    if torch.mean(tmpV[:,0])<0:\n",
    "        tmpV = -tmpV\n",
    "    #plt.plot(tmpV[:,0].cpu(), zorder=0)\n",
    "    S[:,i] = tmpS[:10]\n",
    "#plt.hlines(1/np.sqrt(1000), 0, 1000, color = 'black', zorder=10)\n",
    "plt.plot(alltimes,S.T.cpu())\n",
    "plt.xlabel(\"nb_upd\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alltimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = alltimes[-1]\n",
    "lr = 0.1\n",
    "NGibbs = 100\n",
    "annSteps = 0\n",
    "mb_s = 600\n",
    "num_pcd = 600\n",
    "Nh = torch.tensor(f['W0']).shape[0]\n",
    "Nv = data.shape[1]\n",
    "ep_max = 10\n",
    "w_hat = torch.linspace(0,1,steps=100)\n",
    "_, S_d, V = torch.svd(data)\n",
    "V0 = V[:,0]\n",
    "N = 20000\n",
    "it_mean = 50\n",
    "myRBM = TMCRBM(num_visible=Nv,\n",
    "            num_hidden=Nh,\n",
    "            device=device,\n",
    "            lr=lr,\n",
    "            gibbs_steps=NGibbs,\n",
    "            UpdCentered=False,\n",
    "            mb_s=mb_s,\n",
    "            num_pcd=num_pcd,\n",
    "            N = N,\n",
    "            it_mean = it_mean,\n",
    "           )\n",
    "\n",
    "myRBM.W = torch.tensor(f['W'+str(t)], device = myRBM.device)\n",
    "myRBM.hbias = torch.tensor(f['hbias'+str(t)], device = myRBM.device)\n",
    "myRBM.vbias = torch.tensor(f['vbias'+str(t)], device = myRBM.device)\n",
    "_, _, V = torch.svd(myRBM.W)\n",
    "if torch.mean(V[:,0])<0:\n",
    "    V = -V\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_hat : nDim x nb_point\n",
    "# V : matrice de projection\n",
    "def TMCSampleND(v, w_hat, N, V, it_mcmc=100, it_mean=50, ß=1):\n",
    "    #print(\"Initialisation\")\n",
    "    vtab = torch.zeros(v.shape, device=device)\n",
    "    v_curr = v\n",
    "    norm = 1/(v_curr.shape[0]**0.5)\n",
    "    w_curr = (torch.mm(v_curr.T, V)*norm)[:,:w_hat.shape[0]]\n",
    "    index = torch.randperm(v_curr.shape[0])\n",
    "    for t in range(it_mcmc):\n",
    "        #print('init it')\n",
    "        print(t)\n",
    "        h_curr, _ = myRBM.SampleHiddens01(v_curr)\n",
    "        h_i = (torch.mm(myRBM.W.T, h_curr)+myRBM.vbias.reshape(v.shape[0],1)) # Nv x Ns\n",
    "        w_next = w_curr.clone()\n",
    "        \n",
    "        v_next = torch.clone(v_curr)\n",
    "        index = torch.randperm(v_curr.shape[0])\n",
    "        for idx in range(v_curr.shape[0]):\n",
    "            s = time.time()\n",
    "            i = idx\n",
    "            v_next[i,:] = 1-v_curr[i,:]\n",
    "            for j in range(w_next.shape[1]):\n",
    "                w_next[:,j] += ((2*v_next[i,:]-1)*V[i,j]*norm)\n",
    "                \n",
    "            # On calcul -DeltaE\n",
    "            ΔE = ß*((2*v_next[i,:]-1)*h_i[i,:])-(N/2)*(torch.sum((w_hat.T-w_next)**2, dim=1)-torch.sum((w_hat.T-w_curr)**2, dim=1))\n",
    "\n",
    "            tir = torch.rand(v_curr.shape[1],1, device = torch.device(\"cuda\")).squeeze()\n",
    "            prob = torch.exp(ΔE).squeeze()\n",
    "            v_curr[i,:] = torch.where(tir<prob, v_next[i,:], v_curr[i,:])\n",
    "            v_next[i,:] = torch.where(tir<prob, v_next[i,:], 1-v_next[i,:])\n",
    "            neg_index = torch.ones(w_curr.shape[0], dtype = bool)\n",
    "            index = torch.where(tir<prob)[0]\n",
    "            neg_index[index] = False\n",
    "            w_curr[index,:]=  w_next[index, :]\n",
    "            w_next[neg_index,:] =  w_curr[neg_index,:]\n",
    "            #print(time.time()-s)\n",
    "        if (t>= (it_mcmc-it_mean)):\n",
    "            vtab += v_curr\n",
    "    vtab = vtab*(1/it_mean)\n",
    "    vtab = vtab.reshape(Nv, nb_point, nb_chain)\n",
    "    v_curr = v_curr.reshape(Nv, nb_point, nb_chain)\n",
    "    h_curr = h_curr.reshape(Nh, nb_point, nb_chain)\n",
    "    return v_curr, h_curr, vtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, s, V_g = torch.svd(myRBM.W)\n",
    "if torch.mean(V_g[:,0])<0:\n",
    "    V_g = -V_g\n",
    "proj_data =torch.mm(data, V_g).cpu()/Nv**.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chain = 10 # Nb de chaines pour chaque w_hat\n",
    "it_mcmc = 50 # Nb it_mcmc pour chaque chaine\n",
    "it_mean = 40 # Nb it considérée pour la moyenne temporelle de chaque chaine\n",
    "nDim = 2\n",
    "nb_point_dim = torch.tensor([50,50]) # -> doit avoir autant de terme que la valeur de nDim\n",
    "N = 20000 # Contrainte\n",
    "#nb_point_x = 125 # Nb de points de discrétisation pour w_hat\n",
    "#nb_point_y = 125\n",
    "width_plus = .4\n",
    "limits = torch.zeros((2, nDim))\n",
    "for i in range(nDim):\n",
    "    limits[0, i] = proj_data[:,i].min()-width_plus\n",
    "    limits[1, i] = proj_data[:,i].max()+width_plus\n",
    "\n",
    "xmin = proj_data[:,0].min()-width_plus\n",
    "xmax = proj_data[:,0].max()+width_plus\n",
    "ymin = proj_data[:,1].min()-width_plus\n",
    "ymax = proj_data[:,1].max()+width_plus\n",
    "nb_point = nb_point_dim.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = np.linspace(limits[0,0], limits[1,0], nb_point_dim[0])\n",
    "x_grid = np.array([x_grid for i in range(nb_point_dim[1])])\n",
    "x_grid = x_grid.reshape(nb_point)\n",
    "y_grid = []\n",
    "y_d = np.linspace(limits[0,1], limits[1,1], nb_point_dim[1])\n",
    "for i in range(nb_point_dim[1]):\n",
    "    for j in range(nb_point_dim[0]):\n",
    "        y_grid.append(y_d[i])\n",
    "grid = torch.tensor([x_grid, y_grid], device = device, dtype = dtype)\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = torch.bernoulli(torch.rand(myRBM.Nv, nb_chain*nb_point, device = device))\n",
    "# w_hat = torch.dot(start.T, V)[0:,]\n",
    "w_hat_b = grid\n",
    "w_hat = torch.zeros((2, nb_chain*nb_point), device = device)\n",
    "for i in range(nb_point):\n",
    "    for j in range(nb_chain):\n",
    "        w_hat[:,i*nb_chain+j] = w_hat_b[:,i]\n",
    "tmpv, tmph, vtab = TMCSampleND(start, w_hat, N, V_g, it_mcmc = it_mcmc, it_mean=it_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vinit = torch.bernoulli(torch.rand(\n",
    "        (myRBM.Nv, 10000), device=myRBM.device, dtype=myRBM.dtype))\n",
    "#vinit = torch.where(V_g[:,0]>0, 1, 0).repeat(2000).reshape(myRBM.Nv, 2000).float()\n",
    "#vinit = data.T\n",
    "si, _, _, _ = myRBM.Sampling(vinit, it_mcmc=1000)\n",
    "proj_gen = torch.mm(si.T, V_g).cpu().numpy()/Nv**.5\n",
    "proj_data = torch.mm(data, V_g).cpu().numpy()/Nv**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newy = torch.mm(torch.mean(vtab, dim = 2).T, V_g)[:,:nDim]/myRBM.Nv**0.5\n",
    "#y = torch.mm(vtab.T, V_g)[:,:nDim]/myRBM.Nv**0.5\n",
    "#newy = torch.tensor([torch.mean(y[i*nb_chain:i*nb_chain+nb_chain,:], dim = 0).cpu().numpy() for i in range(nb_point)])\n",
    "#w_hat = w_hat.cpu().numpy()\n",
    "#w_hat_b = w_hat_b.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_pot = newy.T-w_hat_b\n",
    "square = torch.zeros(2, nb_point_dim[0], nb_point_dim[1])\n",
    "w_hat_tmp = np.zeros((2, nb_point_dim[0], nb_point_dim[1]))\n",
    "for i in range(0,grad_pot.shape[1], nb_point_dim[0]):\n",
    "        #print(\\\"I : \\\", i/nb_point_x)\n",
    "        #print(\\\"s : \\\", (i*nb_point_x))\n",
    "        #print(\\\"e : \\\", (i*nb_point_x+nb_point_x))\n",
    "        w_hat_tmp[:,:,int(i/nb_point_dim[0])] = w_hat_b[:, i:(i+nb_point_dim[0])].cpu().numpy()\n",
    "        #print(w_hat_b[:, i:(i+nb_point_dim[0])].cpu().numpy())\n",
    "        square[:,:, int(i/nb_point_dim[0])] = grad_pot[:,i:(i+nb_point_dim[0])]\n",
    "#square = grad_pot.reshape(2,nb_point_dim[0], nb_point_dim[1])\n",
    "w_hat_dim = []\n",
    "for i in range(nDim):\n",
    "    w_hat_dim.append(np.linspace(limits[0,i], limits[1,i], nb_point_dim[i]))\n",
    "\n",
    "res_x = np.zeros(nb_point_dim[0])\n",
    "for i in range(nb_point_dim[0]):\n",
    "    res_x[i] = simps(square[0][:(i+1),0].cpu().numpy(), w_hat_tmp[0,:(i+1),0])\n",
    "res_y = np.zeros((nb_point_dim[0], nb_point_dim[1]))\n",
    "for i in range(nb_point_dim[0]):\n",
    "    for j in range(nb_point_dim[1]):\n",
    "        res_y[i,j] = simps(square[1][i,:(j+1)].cpu().numpy(), w_hat_tmp[1,i,:(j+1)])\n",
    "\n",
    "pot = np.expand_dims(res_x, 1).repeat(nb_point_dim[1],1) + res_y    \n",
    "res = np.exp(N*(pot-np.max(pot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LE CALCUL DE LA CONSTANTE EST CORRECT\n",
    "const = np.zeros(res.shape[0])\n",
    "for i in range(res.shape[0]):\n",
    "    const[i-1] = simps(res[:,i], w_hat_tmp[1, i, :])\n",
    "const = simps(const, w_hat_tmp[0,:,0])\n",
    "p_m = res/const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.zeros(p_m.shape[0])\n",
    "for i in range( p_m.shape[0]):\n",
    "    tmp[i] = simps(p_m[:,i], w_hat_dim[1])\n",
    "tmp = simps(tmp, w_hat_dim[0])\n",
    "print(\"Integrale de la proba sur l'espace : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_i = torch.mean(tmpv, dim = 2)\n",
    "tau_a = torch.mean(tmph, dim = 2)\n",
    "s_i_square = torch.zeros([s_i.shape[0], nb_point_dim[0], nb_point_dim[1]])\n",
    "tau_a_square = torch.zeros([tau_a.shape[0], nb_point_dim[0], nb_point_dim[1]])\n",
    "\n",
    "for i in range(0,grad_pot.shape[1], nb_point_dim[0]):\n",
    "    s_i_square[:,:,int(i/nb_point_dim[0])] = s_i[:, i:(i+nb_point_dim[0])]\n",
    "    tau_a_square[:,:,int(i/nb_point_dim[0])] = tau_a[:, i:(i+nb_point_dim[0])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = torch.zeros(\n",
    "    (Nv, Nh, nb_point), device=device)\n",
    "tmpcompute = torch.zeros(Nv, Nh, nb_chain)\n",
    "s = time.time()\n",
    "for i in range(nb_point):\n",
    "    for k in range(nb_chain):\n",
    "        tmpcompute[:,:,k] = torch.outer(tmpv[:, i, k], tmph[:, i, k])\n",
    "    prod[:, :, i] = torch.mean(tmpcompute, dim = 2)\n",
    "print(\"si tau_a prod : \", time.time()-s)\n",
    "#prod = torch.stack([torch.mean(\n",
    "#    prod[:, :, i*self.nb_chain:i*self.nb_chain+self.nb_chain], dim=2) for i in range(self.nb_point)], 2)\n",
    "\n",
    "p_m = torch.tensor(p_m, device = device)\n",
    "s_i_square = torch.zeros([s_i.shape[0], nb_point_dim[0], nb_point_dim[1]], device=device, dtype=dtype)\n",
    "tau_a_square = torch.zeros([tau_a.shape[0], nb_point_dim[0], nb_point_dim[1]], device=device, dtype=dtype)\n",
    "prod_square = torch.zeros((prod.shape[0], prod.shape[1], nb_point_dim[0], nb_point_dim[1]), device=device, dtype=dtype)\n",
    "for i in range(0,grad_pot.shape[1], nb_point_dim[0]):\n",
    "    s_i_square[:,:,int(i/nb_point_dim[0])] = s_i[:, i:(i+nb_point_dim[0])]\n",
    "    tau_a_square[:,:,int(i/nb_point_dim[0])] = tau_a[:, i:(i+nb_point_dim[0])]\n",
    "    prod_square[:,:,:,int(i/nb_point_dim[0])] = prod[:, :, i:(i+nb_point_dim[0])]\n",
    "\n",
    "tmpres_s_i = torch.zeros(Nv, nb_point_dim[0], device=device, dtype=dtype)\n",
    "tmpres_tau_a = torch.zeros(Nh, nb_point_dim[0], device=device, dtype=dtype)\n",
    "tmpres_prod = torch.zeros((prod_square.shape[0], prod_square.shape[1], prod_square.shape[2]), device=device, dtype=dtype)\n",
    "s_i_square = p_m*s_i_square #Ca fait bien ce qu'on veut\n",
    "tau_a_square = p_m*tau_a_square\n",
    "prod_square = p_m*prod_square\n",
    "s_i_fin = torch.zeros(Nv, device=device, dtype=dtype)\n",
    "tau_a_fin = torch.zeros(Nh, device=device, dtype=dtype)\n",
    "prod_fin = torch.zeros(prod_square.shape[0], prod_square.shape[1], device=device, dtype=dtype)\n",
    "for i in range(nb_point_dim[0]):\n",
    "    tmpres_s_i[:,i] = torch.trapz(s_i_square[:,i,:], torch.tensor(w_hat_dim[1], device=device, dtype=dtype))\n",
    "    tmpres_tau_a[:,i] = torch.trapz(tau_a_square[:,i,:], torch.tensor(w_hat_dim[1], device=device, dtype=dtype))\n",
    "    tmpres_prod[:,:,i] = torch.trapz(prod_square[:,:,i,:], torch.tensor(w_hat_dim[1], device=device, dtype=dtype))\n",
    "tau_a_fin = torch.trapz(tmpres_tau_a, torch.tensor(w_hat_dim[0], device=device, dtype=dtype))\n",
    "s_i_fin = torch.trapz(tmpres_s_i, torch.tensor(w_hat_dim[0], device=device, dtype=dtype))\n",
    "prod_fin = torch.trapz(tmpres_prod, torch.tensor(w_hat_dim[0], device=device, dtype=dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.meshgrid(w_hat_dim[0], w_hat_dim[1])\n",
    "\n",
    "plt.figure(dpi=400)\n",
    "plt.quiver(w_hat_tmp[0], w_hat_tmp[1], square[0].cpu(), square[1].cpu(), scale = 20)\n",
    "plt.contour(w_hat_tmp[0],w_hat_tmp[1], torch.log(p_m.cpu()), 10)\n",
    "plt.scatter(proj_data[:,0], proj_data[:,1])\n",
    "plt.scatter(proj_gen[:,0], proj_gen[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p_m.cpu().T, extent = [xmin, xmax, ymin, ymax])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prod_fin.cpu().numpy().reshape(Nv*Nh), bins = 100);\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = myRBM.getMiniBatches(data.T, 15)\n",
    "v_pos = X\n",
    "h_pos_v, h_pos_m = myRBM.SampleHiddens01(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_pc, _, h_neg_v, h_neg_m = myRBM.GetAv()\n",
    "_, _, h_neg_v_, h_neg_m_ = myRBM.GetAv()\n",
    "v_neg = X_pc\n",
    "v_neg_ = X_pc\n",
    "\n",
    "h_neg_v_save = h_neg_v.clone()\n",
    "NegTerm_ia = h_neg_v.mm(v_neg.t())\n",
    "NegTerm_ia_bad = h_neg_v.mm(v_neg.t())\n",
    "VisDataAv = torch.mean(v_pos, 1)\n",
    "HidDataAv = torch.mean(h_pos_m, 1)\n",
    "Xc_pos = (v_pos.t() - VisDataAv).t()\n",
    "Hc_pos = (h_pos_m.t() - HidDataAv).t()\n",
    "\n",
    "Xc_neg = (v_neg.t() - VisDataAv).t()\n",
    "Hc_neg = (h_neg_m.t() - HidDataAv).t()\n",
    "\n",
    "NormPos = 1.0/mb_s\n",
    "NormNeg = 1.0/num_pcd\n",
    "# NormL2 = self.regL2\n",
    "\n",
    "siτa_neg = Hc_neg.mm(Xc_neg.t())*NormNeg\n",
    "si_neg = torch.sum(v_neg, 1)*NormNeg\n",
    "τa_neg = torch.sum(h_neg_m, 1)*NormNeg\n",
    "\n",
    "ΔW = Hc_pos.mm(Xc_pos.t())*NormPos - siτa_neg\n",
    "\n",
    "ΔW_neg_test = NegTerm_ia*NormNeg - torch.outer(torch.mean(h_neg_m,1).float(), VisDataAv) - \\\n",
    "            torch.outer(HidDataAv, torch.mean(v_neg,1)) + torch.outer(HidDataAv, VisDataAv)\n",
    "\n",
    "ΔW_neg_test_bad = NegTerm_ia_bad*NormNeg - torch.outer(torch.mean(h_neg_v,1).float(), VisDataAv) - \\\n",
    "            torch.outer(HidDataAv, torch.mean(v_neg,1)) + torch.outer(HidDataAv, VisDataAv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(siτa_neg.cpu().numpy().reshape(Nv*Nh), bins = 100);\n",
    "# plt.hist(NegTerm_ia.cpu().numpy().reshape(Nv*Nh)*NormNeg, bins = 80,density=True);\n",
    "plt.title(\"gradient normal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(h_neg_v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((ΔW_neg_test_bad).cpu().numpy().reshape(Nv*Nh), bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.abs(ΔW_neg_test_bad/ΔW_neg_test).cpu().numpy());\n",
    "plt.semilogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ΔW_neg_test.cpu().numpy().reshape(Nv*Nh), bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxxx = (h_neg_v.mm(v_neg.t())/600 - h_neg_m.mm(v_neg.t())/600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.outer(torch.mean(h_neg_v,1).float(), VisDataAv) - torch.outer(torch.mean(h_neg_m,1).float(), VisDataAv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=torch.mean(h_neg_v,1).float() - torch.mean(h_neg_m,1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yy.reshape(100).cpu().numpy(),bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y.reshape(100000).cpu().numpy(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(xxxx.reshape(100000).cpu().numpy(),bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/600**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v_neg.shape)\n",
    "print(torch.mean(h_neg_v,1).shape)\n",
    "VIS = VisDataAv.repeat(600,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(v_neg - VIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, V_d = torch.svd(data.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hat_dim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ΔW.cpu().numpy().reshape(Nv*Nh), bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_neg = s_i_fin\n",
    "h_neg_v = tau_a_fin\n",
    "h_neg_m = prod_fin.T\n",
    "VisDataAv = torch.mean(v_pos, 1).float()\n",
    "HidDataAv = torch.mean(h_pos_m, 1).float()    \n",
    "\n",
    "NormPos = 1.0/mb_s\n",
    "#NormNeg = 1.0/self.num_pcd\n",
    "\n",
    "\n",
    "Xc_pos = (v_pos.t() - VisDataAv).t()\n",
    "Hc_pos = (h_pos_m.t() - HidDataAv).t()\n",
    "\n",
    "si_neg = v_neg\n",
    "τa_neg = h_neg_v\n",
    "print(h_neg_v.shape)\n",
    "print(VisDataAv.shape)\n",
    "print(v_neg.shape)\n",
    "print(HidDataAv.shape)\n",
    "print(torch.outer(HidDataAv, VisDataAv).shape)\n",
    "# ΔW_neg = h_neg_m - torch.outer(h_neg_v.float(), VisDataAv) - torch.outer(HidDataAv, v_neg) + torch.outer(HidDataAv, VisDataAv)\n",
    "ΔW_neg = h_neg_m - torch.outer(torch.mean(h_neg_v_,1).float(), VisDataAv) - torch.outer(HidDataAv, torch.mean(v_neg_,1)) + torch.outer(HidDataAv, VisDataAv)\n",
    "ΔW = Hc_pos.mm(Xc_pos.t())*NormPos - ΔW_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_neg_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(NegTerm_ia.cpu().numpy().reshape(Nv*Nh)*NormNeg, bins = 80,density=True);\n",
    "plt.hist(prod_fin.cpu().numpy().reshape(Nv*Nh), bins =100,density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ΔW_neg.cpu().numpy().reshape(Nv*Nh), bins = 100);\n",
    "# plt.hist(prod_fin.cpu().numpy().reshape(Nv*Nh), bins =100,density=True);\n",
    "plt.title(\"gradient TMC 2D\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(siτa_neg.cpu().numpy().reshape(Nv*Nh), bins = 100);\n",
    "# plt.hist(NegTerm_ia.cpu().numpy().reshape(Nv*Nh)*NormNeg, bins = 80,density=True);\n",
    "plt.title(\"gradient normal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ΔW_neg_test.cpu().numpy().reshape(Nv*Nh), bins = 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(torch.mean(X_pc, 1).cpu().numpy(), density = True, bins = 100, label = \"normal\");\n",
    "plt.hist(s_i_fin.cpu().numpy(), density = True, bins = 100, label = \"TMC\");\n",
    "plt.legend()\n",
    "plt.title(\"negTermV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s_i_fin.cpu(), label = \"TMC\")\n",
    "plt.plot(torch.mean(X_pc, 1).cpu().numpy(), label = \"normal\")\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"negTermV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(torch.mean(h_neg_v_save, 1).cpu().numpy(), label = \"normal\", bins =100)\n",
    "plt.hist(tau_a_fin.cpu().numpy(), label = \"TMC\", bins =100)\n",
    "plt.legend()\n",
    "plt.title(\"negTermH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(torch.mean(h_neg_v_save, 1).cpu().numpy(), label = \"normal\")\n",
    "plt.plot(tau_a_fin.cpu().numpy(), label = \"TMC\")\n",
    "plt.legend()\n",
    "plt.title(\"negTermH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(100):\n",
    "    print('-------------- : ', torch.mm(s_i[:,k].unsqueeze(1).T, V_g)[:,0])\n",
    "    for i in range(10):\n",
    "        proj = torch.mm(tmpv[:,k,i].unsqueeze(1).T, V_g)\n",
    "        print(proj[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
