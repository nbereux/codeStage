{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "sys.path.insert(1, '/home/nicolas/code/src')\n",
    "sys.path.insert(1, '/home/nicolas/code/data')\n",
    "\n",
    "from TMCRBM import TMCRBM\n",
    "from scipy.integrate import simps\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float\n",
    "torch.set_num_threads(4)\n",
    "data = torch.tensor(np.genfromtxt('../dataset/data_2d.dat'), device = device, dtype = dtype)\n",
    "\n",
    "data = (data+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"../model/AllParametersRBM_NGibbs_50_Nh100_Ns1000_Nmb600_Nepoch1000_lr_0.01_TMCTEST2D_updCentered_TRUE.h5\", 'r')\n",
    "alltimes = np.array(f['alltime'])\n",
    "alltimes = []\n",
    "for t in f['alltime'][:]:\n",
    "    if 'W'+str(t) in f:\n",
    "        alltimes.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 4868\n",
    "lr = 0.01\n",
    "NGibbs = 100\n",
    "annSteps = 0\n",
    "mb_s = 600\n",
    "num_pcd = 100\n",
    "Nh = torch.tensor(f['W0']).shape[0]\n",
    "Nv = data.shape[1]\n",
    "ep_max = 10\n",
    "w_hat = torch.linspace(0,1,steps=100)\n",
    "_, S_d, V = torch.svd(data)\n",
    "V0 = V[:,0]\n",
    "N = 20000\n",
    "it_mean = 50\n",
    "myRBM = TMCRBM(num_visible=Nv,\n",
    "            num_hidden=Nh,\n",
    "            device=device,\n",
    "            lr=lr,\n",
    "            gibbs_steps=NGibbs,\n",
    "            UpdCentered=False,\n",
    "            mb_s=mb_s,\n",
    "            num_pcd=num_pcd,\n",
    "            N = N,\n",
    "            it_mean = it_mean,\n",
    "           )\n",
    "\n",
    "myRBM.W = torch.tensor(f['W'+str(t)], device = myRBM.device)\n",
    "myRBM.hbias = torch.tensor(f['hbias'+str(t)], device = myRBM.device)\n",
    "myRBM.vbias = torch.tensor(f['vbias'+str(t)], device = myRBM.device)\n",
    "_, _, V = torch.svd(myRBM.W)\n",
    "if torch.mean(V[:,0])<0:\n",
    "    V = -V\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_hat : nDim x nb_point\n",
    "# V : matrice de projection\n",
    "def TMCSampleND(v, w_hat, N, V, it_mcmc=100, it_mean=50, ß=1):\n",
    "    #print(\"Initialisation\")\n",
    "    vtab = torch.zeros(v.shape, device=device)\n",
    "    v_curr = v\n",
    "    norm = 1/(v_curr.shape[0]**0.5)\n",
    "    w_curr = (torch.mm(v_curr.T, V)*norm)[:,:w_hat.shape[0]]\n",
    "    index = torch.randperm(v_curr.shape[0])\n",
    "    for t in range(it_mcmc):\n",
    "        #print('init it')\n",
    "        print(t)\n",
    "        h_curr, _ = myRBM.SampleHiddens01(v_curr)\n",
    "        h_i = (torch.mm(myRBM.W.T, h_curr)+myRBM.vbias.reshape(v.shape[0],1)) # Nv x Ns\n",
    "        w_next = w_curr.clone()\n",
    "        \n",
    "        v_next = torch.clone(v_curr)\n",
    "        index = torch.randperm(v_curr.shape[0])\n",
    "        for idx in range(v_curr.shape[0]):\n",
    "            s = time.time()\n",
    "            i = idx\n",
    "            v_next[i,:] = 1-v_curr[i,:]\n",
    "            for j in range(w_next.shape[1]):\n",
    "                w_next[:,j] += ((2*v_next[i,:]-1)*V[i,j]*norm)\n",
    "                \n",
    "            # On calcul -DeltaE\n",
    "            ΔE = ß*((2*v_next[i,:]-1)*h_i[i,:])-(N/2)*(torch.sum((w_hat.T-w_next)**2, dim=1)-torch.sum((w_hat.T-w_curr)**2, dim=1))\n",
    "\n",
    "            tir = torch.rand(v_curr.shape[1],1, device = torch.device(\"cuda\")).squeeze()\n",
    "            prob = torch.exp(ΔE).squeeze()\n",
    "            v_curr[i,:] = torch.where(tir<prob, v_next[i,:], v_curr[i,:])\n",
    "            v_next[i,:] = torch.where(tir<prob, v_next[i,:], 1-v_next[i,:])\n",
    "            neg_index = torch.ones(w_curr.shape[0], dtype = bool)\n",
    "            index = torch.where(tir<prob)[0]\n",
    "            neg_index[index] = False\n",
    "            w_curr[index,:]=  w_next[index, :]\n",
    "            w_next[neg_index,:] =  w_curr[neg_index,:]\n",
    "            #print(time.time()-s)\n",
    "        if (t>= (it_mcmc-it_mean)):\n",
    "            vtab += v_curr\n",
    "    vtab = vtab*(1/it_mean)\n",
    "    vtab = vtab.reshape(Nv, nb_point, nb_chain)\n",
    "    v_curr = v_curr.reshape(Nv, nb_point, nb_chain)\n",
    "    h_curr = h_curr.reshape(Nh, nb_point, nb_chain)\n",
    "    return v_curr, h_curr, vtab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, V_g = torch.svd(myRBM.W)\n",
    "if torch.mean(V_g[:,0])<0:\n",
    "    V_g = -V_g\n",
    "proj_data =torch.mm(data, V_g).cpu()/myRBM.Nv**0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_chain = 10 # Nb de chaines pour chaque w_hat\n",
    "it_mcmc = 100 # Nb it_mcmc pour chaque chaine\n",
    "it_mean = 90 # Nb it considérée pour la moyenne temporelle de chaque chaine\n",
    "nDim = 2\n",
    "nb_point_dim = torch.tensor([125, 125]) # -> doit avoir autant de terme que la valeur de nDim\n",
    "N = 20000 # Contrainte\n",
    "#nb_point_x = 125 # Nb de points de discrétisation pour w_hat\n",
    "#nb_point_y = 125\n",
    "width_plus = 0.2\n",
    "limits = torch.zeros((2, nDim))\n",
    "for i in range(nDim):\n",
    "    limits[0, i] = proj_data[:,i].min()-width_plus\n",
    "    limits[1, i] = proj_data[:,i].max()+width_plus\n",
    "\n",
    "xmin = proj_data[:,0].min()-width_plus\n",
    "xmax = proj_data[:,0].max()+width_plus\n",
    "ymin = proj_data[:,1].min()-width_plus\n",
    "ymax = proj_data[:,1].max()+width_plus\n",
    "nb_point = nb_point_dim.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 15625])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_grid = np.linspace(limits[0,0], limits[1,0], nb_point_dim[0])\n",
    "x_grid = np.array([x_grid for i in range(nb_point_dim[1])])\n",
    "x_grid = x_grid.reshape(nb_point)\n",
    "y_grid = []\n",
    "y_d = np.linspace(limits[0,1], limits[1,1], nb_point_dim[1])\n",
    "for i in range(nb_point_dim[0]):\n",
    "    for j in range(nb_point_dim[1]):\n",
    "        y_grid.append(y_d[i])\n",
    "grid = torch.tensor([x_grid, y_grid], device = device, dtype = dtype)\n",
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "start = torch.bernoulli(torch.rand(myRBM.Nv, nb_chain*nb_point, device = device))\n",
    "# w_hat = torch.dot(start.T, V)[0:,]\n",
    "w_hat_b = grid\n",
    "w_hat = torch.zeros((2, nb_chain*nb_point), device = device)\n",
    "for i in range(nb_point):\n",
    "    for j in range(nb_chain):\n",
    "        w_hat[:,i*nb_chain+j] = w_hat_b[:,i]\n",
    "tmpv, tmph, vtab = TMCSampleND(start, w_hat, N, V_g, it_mcmc = it_mcmc, it_mean=it_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newy = torch.mm(torch.mean(vtab, dim = 2).T, V_g)[:,:nDim]/Nv**0.5\n",
    "#y = torch.mm(vtab.T, V_g)[:,:nDim]/myRBM.Nv**0.5\n",
    "#newy = torch.tensor([torch.mean(y[i*nb_chain:i*nb_chain+nb_chain,:], dim = 0).cpu().numpy() for i in range(nb_point)])\n",
    "#w_hat = w_hat.cpu().numpy()\n",
    "#w_hat_b = w_hat_b.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_pot = newy.T-w_hat_b\n",
    "square = torch.zeros(2, nb_point_dim[0], nb_point_dim[1])\n",
    "w_hat_tmp = np.zeros((2, nb_point_dim[0], nb_point_dim[1]))\n",
    "for i in range(0,grad_pot.shape[1], nb_point_dim[0]):\n",
    "        #print(\"I : \", i/nb_point_x)\n",
    "        #print(\"s : \", (i*nb_point_x))\n",
    "        #print(\"e : \", (i*nb_point_x+nb_point_x))\n",
    "        w_hat_tmp[:,:,int(i/nb_point_dim[0])] = w_hat_b[:, i:(i+nb_point_dim[0])].cpu().numpy()\n",
    "        square[:,:, int(i/nb_point_dim[0])] = grad_pot[:,i:(i+nb_point_dim[0])]\n",
    "#square = grad_pot.reshape(2,nb_point_x, nb_point_y)\n",
    "w_hat_dim = []\n",
    "for i in range(nDim):\n",
    "    w_hat_dim.append(np.linspace(limits[0,i], limits[1,i], nb_point_dim[i]))\n",
    "\n",
    "#calcul de l'intégrale sur w_1\n",
    "res_x = np.zeros((nb_point_dim[0],nb_point_dim[1]))\n",
    "for j in range(1,nb_point_dim[1]):\n",
    "    for i in range(1, nb_point_dim[0]):\n",
    "        res_x[i,j] = simps(square[0,:i,j].cpu().numpy(), w_hat_dim[0][:i])\n",
    "\n",
    "res_x = res_x\n",
    "\n",
    "\n",
    "#calcul de l'intégrale sur w_2\n",
    "res_y = np.zeros((nb_point_dim[0], nb_point_dim[1]))\n",
    "for i in range(1, nb_point_dim[0]):\n",
    "    for j in range(1, nb_point_dim[1]):\n",
    "        res_y[i,j] = simps(square[1,i,:j].cpu().numpy(), w_hat_dim[1][:j])\n",
    "res_y = res_y\n",
    "pot = res_x + res_y\n",
    "pot = pot.T\n",
    "res = np.exp(N*(pot-np.max(pot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LE CALCUL DE LA CONSTANTE EST CORRECT\n",
    "const = np.zeros(res.shape[0]-1)\n",
    "for i in range(1, res.shape[0]):\n",
    "    const[i-1] = simps(res[:,i], w_hat_dim[1])\n",
    "const = simps(const, w_hat_dim[1][:-1])\n",
    "p_m = res/const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrale de la proba sur l'espace :  0.9999999999996536\n"
     ]
    }
   ],
   "source": [
    "tmp = np.zeros(p_m.shape[0]-1)\n",
    "for i in range(1, p_m.shape[0]-1):\n",
    "    tmp[i-1] = simps(p_m[:,i], w_hat_dim[1])\n",
    "tmp = simps(tmp, w_hat_dim[1][:-1])\n",
    "print(\"Integrale de la proba sur l'espace : \", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fb3f9adffa0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(p_m, vmax = 1, extent = [limits[0,0], limits[1,0], limits[0,1], limits[1,1]])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_i = torch.stack([torch.mean(\n",
    "            tmpv[:, i*nb_chain:i*nb_chain+nb_chain], dim=1) for i in range(nb_point)], 1)\n",
    "tau_a = torch.stack([torch.mean(\n",
    "    tmph[:, i*nb_chain:i*nb_chain+nb_chain], dim=1) for i in range(nb_point)], 1)\n",
    "\n",
    "s_i_square = torch.zeros([s_i.shape[0], nb_point_dim[0], nb_point_dim[1]])\n",
    "tau_a_square = torch.zeros([tau_a.shape[0], nb_point_dim[0], nb_point_dim[1]])\n",
    "\n",
    "for i in range(0,grad_pot.shape[1], nb_point_dim[0]):\n",
    "    s_i_square[:,:,int(i/nb_point_dim[0])] = s_i[:, i:(i+nb_point_dim[0])]\n",
    "    tau_a_square[:,:,int(i/nb_point_dim[0])] = tau_a[:, i:(i+nb_point_dim[0])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 125, 125])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_i_square.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_m = torch.tensor(p_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpres = torch.zeros(1000,125)\n",
    "tmps_i_square = p_m*s_i_square\n",
    "s_i_fin = torch.zeros(1000)\n",
    "for i in range(nb_point_dim[0]):\n",
    "    tmpres[:,i] = torch.trapz(tmps_i_square[:,i,:-1], torch.tensor(w_hat_dim[1][:-1]))\n",
    "s_i_fin = torch.trapz(tmpres[:,:-1], torch.tensor(w_hat_dim[0][:-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 15625])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
